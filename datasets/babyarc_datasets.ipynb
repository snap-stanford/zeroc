{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo for integration with the BabyARC engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..', '..'))\n",
    "from reasoning.concept_env.BabyARC.code.dataset.dataset import *\n",
    "\n",
    "# Demo Imports (You don't have to import these in case for running in a separate script)\n",
    "from reasoning.util import get_root_dir\n",
    "from reasoning.util import to_Variable_recur, visualize_dataset, visualize_matrices\n",
    "\n",
    "# random seeds\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# global vars\n",
    "RUN_AS_CREATOR = False\n",
    "ARC_OBJ_LOADED = False\n",
    "DEMO_MAX_ARC_OBJS = 500\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "import logging\n",
    "FORMAT = \"%(asctime)-15s %(message)s\"\n",
    "logging.basicConfig(format=FORMAT, level=logging.DEBUG,\n",
    "                    datefmt=\"%Y-%m-%d %H:%M\")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-loaded Object File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    arc_obj_dir = os.path.join(get_root_dir(), 'concept_env/datasets/arc_objs.pt')\n",
    "    arc_objs = torch.load(arc_obj_dir)\n",
    "    logger.info(\"SUCCESS! You loaded the pre-collected object file from ARC!\")\n",
    "    ARC_OBJ_LOADED = True\n",
    "except:\n",
    "    logger.info(\"Please check if obejct file in the directory indicated above!\")\n",
    "    logger.info(f\"WARNING: Please get those pre-collected ARC objects in {arc_obj_dir}!\")\n",
    "    logger.info(\"You can download this file from: https://drive.google.com/file/d/1dZhT1cUFGvivJbSTwnqjou2uilLXffGY/view?usp=sharing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObE = ObjectEngine()\n",
    "# Below the log, it should shows how many objects it loads.\n",
    "# Iso obj means the count of unique objects (considering rotations, color permutations, etc..)\n",
    "_ = ObE.sample_objs_with_composite_shape(\n",
    "    n=1, w_lims=[16,16], h_lims=[16,16], \n",
    "    rainbow_prob=0.0, chosen_concept=\"RectE1a\",\n",
    "    n_retry=30,\n",
    ")\n",
    "# If no error, that means you successfully sampled an object!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object Engine sampling with ARC Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObE = ObjectEngine()\n",
    "# Below the log, it should shows how many objects it loads.\n",
    "# Iso obj means the count of unique objects (considering rotations, color permutations, etc..)\n",
    "test_canvas = CanvasEngine().sameple_canvas()[0]\n",
    "objs1 = ObE.sample_objs_with_composite_shape(\n",
    "    n=1, w_lims=[16,16], h_lims=[16,16], \n",
    "    rainbow_prob=0.0, chosen_concept=\"RectE1a\",\n",
    "    n_retry=30,\n",
    ")[0]\n",
    "if objs1 != None:\n",
    "    # Here is just one example with how you can sample different objects from the object engine!\n",
    "    results = test_canvas.placement(objs1)\n",
    "    if results == -1:\n",
    "        logger.info(\"Placement step failed! Please rerun!\")\n",
    "    else:\n",
    "        test_canvas.render(minimum_cover=False)\n",
    "else:\n",
    "    logger.info(\"Placement step failed! Please rerun!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canvas Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_canvas = CanvasEngine().sameple_canvas()[0]\n",
    "objs1 = ObE.sample_objs_with_line(n=1, len_lims=[5,5], thickness=1, rainbow_prob=0.0, direction=\"h\")\n",
    "# Here is just one example with how you can sample different objects from the object engine!\n",
    "results = test_canvas.placement(objs1[0])\n",
    "if results == -1:\n",
    "    logger.info(\"Placement step failed! Please rerun!\")\n",
    "else:\n",
    "    test_canvas.render(minimum_cover=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_canvas = CanvasEngine().sameple_canvas()[0]\n",
    "objs1 = ObE.sample_objs_with_l_shape(n=1, w_lims=[5,5], h_lims=[7,7], thickness=1, rainbow_prob=0.2, direction=3)[0]\n",
    "objs1 = ObE.fix_color(objs1, 1)\n",
    "# Here is just one example with how you can sample different objects from the object engine!\n",
    "results = test_canvas.placement(objs1)\n",
    "if results == -1:\n",
    "    logger.info(\"Placement step failed! Please rerun!\")\n",
    "else:\n",
    "    test_canvas.render(minimum_cover=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Objects.\n",
    "test_canvas = CanvasEngine().sameple_canvas()[0]\n",
    "objs1 = ObE.sample_objs_with_random_shape(n=1, w_lims=[4,4], h_lims=[4,4], rainbow_prob=0.0)[0]\n",
    "objs1 = ObE.fix_color(objs1, 2)\n",
    "# Here is just one example with how you can sample different objects from the object engine!\n",
    "results = test_canvas.placement(objs1)\n",
    "if results == -1:\n",
    "    logger.info(\"Placement step failed! Please rerun!\")\n",
    "else:\n",
    "    test_canvas.render(minimum_cover=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BabyARC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_dataset = \\\n",
    "    BabyARCDataset(\n",
    "    pretrained_obj_cache=None,\n",
    "    save_directory=\"./BabyARCDataset/\", \n",
    "    object_limit=1, \n",
    "    noise_level=0, \n",
    "    canvas_size=16,\n",
    "    skip_load_pretrain_obj=True,\n",
    ") # canvas makes w=h canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inplace object placement.\n",
    "canvas_dict = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict(\n",
    "        [(('obj_0', 'obj_1'), 'IsNonOverlapXY'),\n",
    "        ]\n",
    "    ), \n",
    "    color_avail=[1,2],\n",
    "    rainbow_prob=0.0,\n",
    "    allow_connect=True, \n",
    "    parsing_check=True,\n",
    "    concept_collection=[\"Eshape\", \"rectangle\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_w = np.random.randint(5, 17)\n",
    "out_h = np.random.randint(5, 17)\n",
    "in_w = np.random.randint(4, out_w)\n",
    "in_h = np.random.randint(4, out_h)\n",
    "char_w = np.random.randint(3, 9)\n",
    "char_h = np.random.randint(5, 9)\n",
    "            \n",
    "# Inplace object placement.\n",
    "canvas_dict_1b = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict(\n",
    "        [(('obj_0', f'rectangle_[{out_w},{out_h}]'), 'Attr'), \n",
    "         (('obj_1', f'rectangle_[{in_w},{in_h}]'), 'Attr'), \n",
    "         (('obj_0', 'obj_1'), 'IsOutside'),\n",
    "         (('obj_2', f'Eshape_[{char_w},{char_h}]'), 'Attr'),\n",
    "         # (('obj_1', 'obj_2'), 'SameColor'),\n",
    "        ]\n",
    "    ), \n",
    "    color_avail=[1,2,3,4,5,6,7,8,9],\n",
    "    rainbow_prob=0.0,\n",
    "    allow_connect=True, \n",
    "    concept_collection=[\"Eshape\"],\n",
    "    large_shape=True,\n",
    "    parsing_check=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_w = np.random.randint(5, 17)\n",
    "out_h = np.random.randint(5, 17)\n",
    "in_w = np.random.randint(4, out_w)\n",
    "in_h = np.random.randint(4, out_h)\n",
    "char_w = np.random.randint(3, 9)\n",
    "char_h = np.random.randint(5, 9)\n",
    "            \n",
    "# Inplace object placement.\n",
    "canvas_dict_1c = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict(\n",
    "        [(('obj_0', f'rectangle_[{out_w},{out_h}]'), 'Attr'), \n",
    "         (('obj_1', f'rectangle_[{in_w},{in_h}]'), 'Attr'), \n",
    "         (('obj_0', 'obj_1'), 'IsOutside'),\n",
    "         (('obj_2', f'Eshape_[{char_w},{char_h}]'), 'Attr'),\n",
    "         (('obj_1', 'obj_2'), 'SameColor'),\n",
    "        ]\n",
    "    ), \n",
    "    color_avail=[1,2,3,4,5,6,7,8,9],\n",
    "    rainbow_prob=0.0,\n",
    "    allow_connect=True, \n",
    "    concept_collection=[\"Eshape\"],\n",
    "    large_shape=True,\n",
    "    parsing_check=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_w = np.random.randint(5, 17)\n",
    "out_h = np.random.randint(5, 17)\n",
    "in_w = np.random.randint(4, 8)\n",
    "in_h = np.random.randint(4, 8)\n",
    "char_w = np.random.randint(3, 8)\n",
    "char_h = np.random.randint(5, 8)\n",
    "            \n",
    "# Inplace object placement.\n",
    "canvas_dict_2b = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict(\n",
    "        [(('obj_0', f'rectangle_[{out_w},{out_h}]'), 'Attr'), \n",
    "         (('obj_1', f'rectangle_[{in_w},{in_h}]'), 'Attr'), \n",
    "         (('obj_0', 'obj_1'), 'IsOutside'),\n",
    "         (('obj_2', f'Eshape_[{char_w},{char_h}]'), 'Attr'),\n",
    "         (('obj_0', 'obj_2'), 'IsOutside'),\n",
    "         # (('obj_1', 'obj_2'), 'SameColor'),\n",
    "        ]\n",
    "    ), \n",
    "    color_avail=[1,2,3,4,5,6,7,8,9],\n",
    "    rainbow_prob=0.0,\n",
    "    allow_connect=True, \n",
    "    concept_collection=[\"Eshape\"],\n",
    "    large_shape=True,\n",
    "    parsing_check=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_w = np.random.randint(12, 17)\n",
    "out_h = np.random.randint(12, 17)\n",
    "in_w = np.random.randint(5, 8)\n",
    "in_h = np.random.randint(5, 8)\n",
    "char_w = np.random.randint(3, 8)\n",
    "char_h = np.random.randint(5, 8)\n",
    "            \n",
    "# Inplace object placement.\n",
    "canvas_dict_2c = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict(\n",
    "        [(('obj_0', f'rectangle_[{out_w},{out_h}]'), 'Attr'), \n",
    "         (('obj_1', f'rectangle_[{in_w},{in_h}]'), 'Attr'), \n",
    "         (('obj_0', 'obj_1'), 'IsOutside'),\n",
    "         (('obj_2', f'Eshape_[{char_w},{char_h}]'), 'Attr'),\n",
    "         (('obj_0', 'obj_2'), 'IsOutside'),\n",
    "         (('obj_1', 'obj_2'), 'SameColor'),\n",
    "        ]\n",
    "    ), \n",
    "    color_avail=[1,2,3,4,5,6,7,8,9],\n",
    "    rainbow_prob=0.0,\n",
    "    allow_connect=True, \n",
    "    concept_collection=[\"Eshape\"],\n",
    "    large_shape=True,\n",
    "    parsing_check=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_w = np.random.randint(9, 17)\n",
    "out_h = np.random.randint(9, 17)\n",
    "in_w = np.random.randint(7, out_w-1)\n",
    "in_h = np.random.randint(7, out_h-1)\n",
    "char_w = np.random.randint(3, in_w-1)\n",
    "char_h = np.random.randint(5, in_h-1)\n",
    "            \n",
    "# Inplace object placement.\n",
    "canvas_dict_3b = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict(\n",
    "        [\n",
    "         (('obj_0', f'rectangle_[{out_w},{out_h}]'), 'Attr'), \n",
    "         (('obj_1', f'rectangle_[{in_w},{in_h}]'), 'Attr'), \n",
    "         (('obj_0', 'obj_1'), 'IsOutside'),\n",
    "         (('obj_2', f'Eshape_[{char_w},{char_h}]'), 'Attr'), \n",
    "         (('obj_1', 'obj_2'), 'IsOutside'),\n",
    "         # (('obj_1', 'obj_2'), 'SameColor'),\n",
    "        ]\n",
    "    ), \n",
    "    color_avail=[1,2,3,4,5,6,7,8,9],\n",
    "    rainbow_prob=0.0,\n",
    "    allow_connect=True, \n",
    "    concept_collection=[\"Ashape\"],\n",
    "    large_shape=True,\n",
    "    parsing_check=True,\n",
    "    axis_off=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_w = np.random.randint(9, 17)\n",
    "out_h = np.random.randint(9, 17)\n",
    "in_w = np.random.randint(7, out_w-1)\n",
    "in_h = np.random.randint(7, out_h-1)\n",
    "char_w = np.random.randint(3, in_w-1)\n",
    "char_h = np.random.randint(5, in_h-1)\n",
    "            \n",
    "# Inplace object placement.\n",
    "canvas_dict_3c = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict(\n",
    "        [\n",
    "         (('obj_0', f'rectangle_[{out_w},{out_h}]'), 'Attr'), \n",
    "         (('obj_1', f'rectangle_[{in_w},{in_h}]'), 'Attr'), \n",
    "         (('obj_0', 'obj_1'), 'IsOutside'),\n",
    "         (('obj_2', f'Eshape_[{char_w},{char_h}]'), 'Attr'), \n",
    "         (('obj_1', 'obj_2'), 'IsOutside'),\n",
    "         # (('obj_1', 'obj_2'), 'SameColor'),\n",
    "        ]\n",
    "    ), \n",
    "    color_avail=[1,2,3,4,5,6,7,8,9],\n",
    "    rainbow_prob=0.0,\n",
    "    allow_connect=True, \n",
    "    concept_collection=[\"Ashape\"],\n",
    "    large_shape=True,\n",
    "    parsing_check=True,\n",
    "    axis_off=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inplace object placement.\n",
    "canvas_dict = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict(\n",
    "        [(('obj_0', 'rectangle_[10,12]'), 'Attr'), \n",
    "         (('obj_1', 'rectangle_[6,6]'), 'Attr'), \n",
    "         (('obj_1', 'obj_0'), 'IsInside'),\n",
    "         (('obj_2', 'Ashape_[3,6]'), 'Attr'),\n",
    "         (('obj_1', 'obj_2'), 'SameColor'),\n",
    "        ]\n",
    "    ), \n",
    "    color_avail=[1,2,3,4,5,6,7,8,9],\n",
    "    rainbow_prob=0.0,\n",
    "    allow_connect=False, \n",
    "    concept_collection=[\"Eshape\"],\n",
    "    large_shape=True,\n",
    "    parsing_check=True,\n",
    "    is_plot=True,\n",
    ")\n",
    "if canvas_dict != -1:\n",
    "    mid_ax_y_l = canvas_dict[\"id_position_map\"][1][0].tolist() + (canvas_dict[\"id_object_map\"][1].shape[0])//2\n",
    "    mid_ax_x_l = canvas_dict[\"id_position_map\"][1][1].tolist() + (canvas_dict[\"id_object_map\"][1].shape[1])//2\n",
    "\n",
    "    mid_ax_y_r = canvas_dict[\"id_position_map\"][2][0].tolist() + (canvas_dict[\"id_object_map\"][2].shape[0])//2\n",
    "    mid_ax_x_r = canvas_dict[\"id_position_map\"][2][1].tolist() + (canvas_dict[\"id_object_map\"][2].shape[1])//2\n",
    "    \n",
    "    if abs(mid_ax_y_l-mid_ax_y_r) <= 2 or abs(mid_ax_x_l-mid_ax_x_r) <= 2:\n",
    "        failed = False\n",
    "        if ('obj_2', 'obj_0') in canvas_dict[\"partial_relation_edges\"]:\n",
    "            if \"IsInside\" in canvas_dict[\"partial_relation_edges\"][('obj_2', 'obj_0')]:\n",
    "                failed = True\n",
    "        if ('obj_2', 'obj_1') in canvas_dict[\"partial_relation_edges\"]:\n",
    "            if \"IsInside\" in canvas_dict[\"partial_relation_edges\"][('obj_2', 'obj_1')]:\n",
    "                failed = True\n",
    "        if not failed:\n",
    "            in_canvas = Canvas(\n",
    "                repre_dict=canvas_dict\n",
    "            )\n",
    "            in_canvas.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inplace object placement.\n",
    "canvas_dict = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict(\n",
    "        [(('obj_0', 'rectangle_[10,10]'), 'Attr'), \n",
    "         (('obj_1', 'Eshape_[3,6]'), 'Attr'),\n",
    "         (('obj_1', 'obj_0'), 'IsInside'),\n",
    "         (('obj_2', 'rectangle_[3,3]'), 'Attr'), \n",
    "        ]\n",
    "    ), \n",
    "    color_avail=[1,2,3,4,5,6,7,8,9],\n",
    "    rainbow_prob=0.0,\n",
    "    allow_connect=False, \n",
    "    concept_collection=[\"Eshape\"],\n",
    "    large_shape=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inplace object placement.\n",
    "canvas_dict = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict(\n",
    "        [(('obj_0', 'rectangle_[10,10]'), 'Attr'), \n",
    "         (('obj_1', 'Eshape_[3,6]'), 'Attr'),\n",
    "         (('obj_2', 'rectangle_[3,3]'), 'Attr'), \n",
    "        ]\n",
    "    ), \n",
    "    color_avail=[1,2,3,4,5,6,7,8,9],\n",
    "    rainbow_prob=0.0,\n",
    "    allow_connect=False, \n",
    "    concept_collection=[\"Eshape\"],\n",
    "    large_shape=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inplace object placement.\n",
    "canvas_dict = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict(\n",
    "        [(('obj_0', 'rectangle_[13,13]'), 'Attr'), \n",
    "         (('obj_1', 'rectangle_[9,9]'), 'Attr'), \n",
    "         (('obj_2', 'obj_1'), 'IsInside'), \n",
    "        ]\n",
    "    ), \n",
    "    color_avail=[1,2,3,4,5,6,7,8,9],\n",
    "    rainbow_prob=0.0,\n",
    "    allow_connect=False, \n",
    "    concept_collection=[\"Eshape\"],\n",
    "    large_shape=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With fixed color collections.\n",
    "canvas_dict = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict([(('obj_0', 'rectangleSolid_[-1,-1]'), 'Attr')\n",
    "                ]), \n",
    "    allow_connect=True, \n",
    "    color_avail=[1,2,3],\n",
    "    rainbow_prob=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas_dict = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict([(('obj_0', 'rectangleSolid_[-1,-1]'), 'Attr')\n",
    "                ]), \n",
    "    allow_connect=True, \n",
    "    color_collection=None,\n",
    "    rainbow_prob=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Some current supported DSLs in relational canvas.\n",
    "# ('obj_*', 'color_[c]'), 'Attr')\n",
    "# ('obj_*', 'pos_[i,j]'), 'Attr')\n",
    "# ('obj_*', 'boundary_attachment_[b({0(u),1(r),2(l),3(l)})]'), 'Attr')\n",
    "# ('obj_*', 'pixel'), 'Attr')\n",
    "# ('obj_*', 'line_[l,t,d({-1,0(v),1(h)})]'), 'Attr')\n",
    "# ('obj_*', 'reactangle_[w,h]'), 'Attr')\n",
    "# ('obj_*', 'enclosure_[w,h,g({-1,0(ng),1(g)})]'), 'Attr')\n",
    "# ('obj_*', 'obj_*'), '[AnyRelation]')\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_dataset = \\\n",
    "    BabyARCDataset(pretrained_obj_cache=os.path.join(get_root_dir(), 'concept_env/datasets/arc_objs.pt'),\n",
    "                   save_directory=\"./BabyARCDataset/\", \n",
    "                   object_limit=1, noise_level=0, \n",
    "                   canvas_size=8) # canvas makes w=h canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this does not return, simply rerun!\n",
    "canvas_dict = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict([(('obj_0', 'obj_1'), 'SameColor')]),\n",
    "    allow_connect=True, \n",
    "    color_avail=[1],\n",
    "    rainbow_prob=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another case for vertical and horizontal lines.\n",
    "canvas_dict = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict([(('obj_0', 'line_[6,1,0]'), 'Attr'), \n",
    "                 (('obj_1', 'line_[7,1,1]'), 'Attr')]), \n",
    "    allow_connect=True,\n",
    "    color_avail=[1,2,3],\n",
    "    rainbow_prob=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complex relations.\n",
    "canvas_dict = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict([(('obj_0', 'line_[5,1,0]'), 'Attr'), \n",
    "                 (('obj_1', 'line_[7,1,0]'), 'Attr'),\n",
    "                 (('obj_0', 'boundary_attachment_[2]'), 'Attr'),\n",
    "                 (('obj_1', 'boundary_attachment_[2]'), 'Attr')]), \n",
    "    color_collection=[1,2,3],\n",
    "    rainbow_prob=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Massive generation checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "dataset = BabyARCDataset(\n",
    "    pretrained_obj_cache=os.path.join(get_root_dir(), 'concept_env/datasets/arc_objs.pt'),\n",
    "    save_directory=get_root_dir() + \"/concept_env/BabyARCDataset/\", \n",
    "    object_limit=0,\n",
    "    noise_level=0, \n",
    "    canvas_size=8,\n",
    ")\n",
    "mode = \"Line\"\n",
    "examples_all = []\n",
    "masks_all = []\n",
    "concepts_all = []\n",
    "max_n_objs = 3\n",
    "if mode == \"Line\":\n",
    "    for i in range(10000):\n",
    "        n_objs = np.random.randint(max_n_objs+1)\n",
    "        List = [(('obj_{}'.format(i), 'line_[-1,1,-1]'), 'Attr') for i in range(n_objs)]\n",
    "        canvas_dict = dataset.sample_single_canvas_by_core_edges(\n",
    "            OrderedDict(List))\n",
    "        if canvas_dict != -1:\n",
    "            n_sampled_objs = len(canvas_dict['id_object_mask'])\n",
    "            assert n_sampled_objs == n_objs\n",
    "            examples_all += [canvas_dict[\"image_t\"]] * n_sampled_objs\n",
    "            masks_all += list(canvas_dict['id_object_mask'].values())\n",
    "            concepts_all += [\"Line\"] * n_sampled_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using dataset interface to sample canvas now.\n",
    "demo_dataset = \\\n",
    "    BabyARCDataset(pretrained_obj_cache=os.path.join(get_root_dir(), 'concept_env/datasets/arc_objs.pt'),\n",
    "                   save_directory=\"./BabyARCDataset/\", \n",
    "                   object_limit=1, noise_level=0, canvas_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repre_dict_1 = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict([(('obj_0', 'randomShape_[2,4]'), 'Attr')]), \n",
    "    allow_connect=True, is_plot=False, rainbow_prob=0.0\n",
    ")\n",
    "if repre_dict_1 == -1:\n",
    "    print(\"CANVAS FAILED!\")\n",
    "else:\n",
    "    in_canvas_1 = Canvas(\n",
    "        repre_dict=repre_dict_1\n",
    "    )\n",
    "    in_canvas_1.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BabyARC with Rotation Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_dataset = \\\n",
    "    BabyARCDataset(pretrained_obj_cache=os.path.join(get_root_dir(), 'concept_env/datasets/arc_objs.pt'),\n",
    "                   save_directory=\"./BabyARCDataset/\", \n",
    "                   object_limit=1, noise_level=0, canvas_size=20)\n",
    "\n",
    "repre_dict_1 = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict([(('obj_0', 'line_[6,1,0]'), 'Attr'), \n",
    "                 (('obj_1', 'line_[7,1,1]'), 'Attr')]), \n",
    "    allow_connect=True, is_plot=False\n",
    ")\n",
    "in_canvas_1 = Canvas(\n",
    "    repre_dict=repre_dict_1\n",
    ")\n",
    "\n",
    "repre_dict_2 = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict([(('obj_0', 'line_[6,1,0]'), 'Attr'), \n",
    "                 (('obj_1', 'line_[7,1,1]'), 'Attr')]), \n",
    "    allow_connect=True, is_plot=False\n",
    ")\n",
    "in_canvas_2 = Canvas(\n",
    "    repre_dict=repre_dict_2\n",
    ")\n",
    "\n",
    "if in_canvas_1 == -1 or in_canvas_2 == -1:\n",
    "    print(\"CANVAS FAILED!\")\n",
    "\n",
    "out_canvas_list, _ = OperatorEngine().operate_rotate(\n",
    "    [in_canvas_1, in_canvas_2], [[\"obj_0\"], [\"obj_1\"]],\n",
    "    operator_tag=\"#RotateA\", \n",
    "    allow_connect=True, allow_shape_break=False\n",
    ")\n",
    "if out_canvas_list == -1:\n",
    "    print(\"OPERATOR FAILED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = in_canvas_1.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = out_canvas_list[0].render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relations and different options (e.g., shape break option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_dataset = \\\n",
    "    BabyARCDataset(pretrained_obj_cache=os.path.join(get_root_dir(), 'concept_env/datasets/arc_objs.pt'),\n",
    "                   save_directory=\"./BabyARCDataset/\", \n",
    "                   object_limit=1, noise_level=0, canvas_size=10)\n",
    "\n",
    "repre_dict_1 = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict([(('obj_0', 'line_[6,1,0]'), 'Attr'), \n",
    "                 (('obj_1', 'line_[7,1,1]'), 'Attr')]), \n",
    "    allow_connect=True, is_plot=False\n",
    ")\n",
    "in_canvas_1 = Canvas(\n",
    "    repre_dict=repre_dict_1\n",
    ")\n",
    "\n",
    "repre_dict_2 = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict([(('obj_0', 'line_[6,1,0]'), 'Attr'), \n",
    "                 (('obj_1', 'line_[7,1,1]'), 'Attr')]), \n",
    "    allow_connect=True, is_plot=False\n",
    ")\n",
    "in_canvas_2 = Canvas(\n",
    "    repre_dict=repre_dict_2\n",
    ")\n",
    "\n",
    "if in_canvas_1 == -1 or in_canvas_2 == -1:\n",
    "    print(\"CANVAS FAILED!\")\n",
    "\n",
    "out_canvas_list, _ = OperatorEngine().operate_rotate(\n",
    "    [in_canvas_1, in_canvas_2], [[\"obj_0\"], [\"obj_1\"]],\n",
    "    operator_tag=\"#RotateA\", \n",
    "    allow_connect=True, allow_shape_break=True\n",
    ")\n",
    "if out_canvas_list == -1:\n",
    "    print(\"OPERATOR FAILED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = in_canvas_1.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = out_canvas_list[0].render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lshape\n",
    "demo_dataset = \\\n",
    "    BabyARCDataset(pretrained_obj_cache=os.path.join(get_root_dir(), 'concept_env/datasets/arc_objs.pt'),\n",
    "                   save_directory=\"./BabyARCDataset/\", \n",
    "                   object_limit=1, noise_level=0, canvas_size=5)\n",
    "\n",
    "# multiple L shapes\n",
    "repre_dict_1 = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict([(('obj_0', 'Lshape_[2,3,0]'), 'Attr'),\n",
    "                 (('obj_1', 'Lshape_[2,3,3]'), 'Attr'),\n",
    "                 (('obj_2', 'Lshape_[2,3,1]'), 'Attr')\n",
    "                ]), \n",
    "    allow_connect=True, is_plot=True, rainbow_prob=0.0\n",
    ")\n",
    "in_canvas_1 = Canvas(\n",
    "    repre_dict=repre_dict_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Symmetry shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symmetry objects\n",
    "demo_dataset = \\\n",
    "    BabyARCDataset(pretrained_obj_cache=os.path.join(get_root_dir(), 'concept_env/datasets/arc_objs.pt'),\n",
    "                   save_directory=\"./BabyARCDataset/\", \n",
    "                   object_limit=1, noise_level=0, canvas_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repre_dict_1 = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict([(('obj_0', 'symmetry_[4,6]_[0]'), 'Attr')]), # the second list the symmetry axis [0 (-), 1(|), 2(\\), 3(/)]\n",
    "    allow_connect=True, is_plot=True, rainbow_prob=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARC shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity operator\n",
    "demo_dataset = \\\n",
    "    BabyARCDataset(pretrained_obj_cache=os.path.join(get_root_dir(), 'concept_env/datasets/arc_objs.pt'),\n",
    "                   save_directory=\"./BabyARCDataset/\", \n",
    "                   object_limit=None, noise_level=0, canvas_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple L shapes\n",
    "repre_dict_1 = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict([(('obj_0', 'arcShape_[4,4]'), 'Attr')]), \n",
    "    allow_connect=True, is_plot=True, rainbow_prob=0.0\n",
    ")\n",
    "in_canvas_1 = Canvas(\n",
    "    repre_dict=repre_dict_1\n",
    ")\n",
    "_ = in_canvas_1.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo for outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lshape\n",
    "demo_dataset = \\\n",
    "    BabyARCDataset(pretrained_obj_cache=os.path.join(get_root_dir(), 'concept_env/datasets/arc_objs.pt'),\n",
    "                   save_directory=\"./BabyARCDataset/\", \n",
    "                   object_limit=1, noise_level=0, canvas_size=5)\n",
    "\n",
    "# multiple L shapes\n",
    "repre_dict_1 = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict([(('obj_0', 'Lshape_[2,3,0]'), 'Attr'),\n",
    "                 (('obj_1', 'Lshape_[2,3,3]'), 'Attr'),\n",
    "                 (('obj_2', 'Lshape_[2,3,1]'), 'Attr')\n",
    "                ]), \n",
    "    allow_connect=True, is_plot=True, rainbow_prob=0.0\n",
    ")\n",
    "in_canvas_1 = Canvas(\n",
    "    repre_dict=repre_dict_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also load a canvas by a single image tensor!\n",
    "arc_canvas_dict = demo_dataset.sample_task_canvas_from_arc(repre_dict_1[\"image_t\"]) # as a image tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_canvas_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operator: Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity operator\n",
    "demo_dataset = \\\n",
    "    BabyARCDataset(pretrained_obj_cache=os.path.join(get_root_dir(), 'concept_env/datasets/arc_objs.pt'),\n",
    "                   save_directory=\"./BabyARCDataset/\", \n",
    "                   object_limit=1, noise_level=0, canvas_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple L shapes\n",
    "repre_dict_1 = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict([(('obj_0', 'Lshape_[2,3,0]'), 'Attr'),\n",
    "                 (('obj_1', 'Lshape_[2,3,3]'), 'Attr'),\n",
    "                 (('obj_2', 'Lshape_[2,3,1]'), 'Attr')\n",
    "                ]), \n",
    "    allow_connect=True, is_plot=True, rainbow_prob=0.0\n",
    ")\n",
    "in_canvas_1 = Canvas(\n",
    "    repre_dict=repre_dict_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_canvas_list, _ = OperatorEngine().operator_identity(\n",
    "    [in_canvas_1], [[\"obj_0\"]],\n",
    "    inplace=False\n",
    ")\n",
    "if out_canvas_list == -1:\n",
    "    print(\"OPERATOR FAILED!\")\n",
    "_ = out_canvas_list[0].render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_canvas_list[0].repr_as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = in_canvas_1.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operator: Move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move operator\n",
    "# this can also be used to mimic object chasing etc..\n",
    "out_canvas_list, _ = OperatorEngine().operator_move(\n",
    "    [in_canvas_1], [[\"obj_0\"]], [[OperatorMoveSpec(autonomous=False,\n",
    "                                                   direction=1, \n",
    "                                                   distance=-1, \n",
    "                                                   hit_type=None, # either wall or agent\n",
    "                                                   linkage_move=False, \n",
    "                                                   linkage_move_distance_ratio=None\n",
    "                                                  )]], \n",
    "    allow_overlap=False, \n",
    "    allow_shape_break=True,\n",
    "    allow_connect=True,\n",
    ")\n",
    "if out_canvas_list == -1:\n",
    "    print(\"OPERATOR FAILED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = out_canvas_list[0].render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can add a second ops on this initermediate output canvas\n",
    "out_canvas_list_2, _ = OperatorEngine().operate_rotate(\n",
    "    [out_canvas_list[0]], [[\"obj_1\"]],\n",
    "    operator_tag=\"#RotateA\", \n",
    "    allow_connect=True, allow_shape_break=False\n",
    ")\n",
    "if out_canvas_list_2 == -1:\n",
    "    print(\"OPERATOR FAILED!\")\n",
    "_ = out_canvas_list_2[0].render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation: relation and concept collection based sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More relation with BabyARC objects\n",
    "demo_dataset = \\\n",
    "    BabyARCDataset(pretrained_obj_cache=os.path.join(get_root_dir(), 'concept_env/datasets/arc_objs.pt'),\n",
    "                   save_directory=\"./BabyARCDataset/\", \n",
    "                   object_limit=1, noise_level=0, canvas_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change the first order relation here with the following options:\n",
    "\"\"\"\n",
    "\"SameAll\", \"SameShape\", \"SameColor\", \"SameRow\", \"SameCol\", \"IsInside\", \"IsTouch\"\n",
    "\n",
    "concept_collection will constraint the kind of shape you will see.\n",
    "\"\"\"\n",
    "canvas_dict = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict([(('obj_0', 'obj_1'), 'IsTouch')\n",
    "                ]), \n",
    "    allow_connect=True, rainbow_prob=0.0, \n",
    "    concept_collection=[\"line\", \"randomShape\"], \n",
    "    is_plot=True\n",
    ")\n",
    "if canvas_dict == -1:\n",
    "    print(\"CANVAS PLACEMENT FAILED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same Color + IsTouch + Move\n",
    "demo_dataset = \\\n",
    "    BabyARCDataset(pretrained_obj_cache=os.path.join(get_root_dir(), 'concept_env/datasets/arc_objs.pt'),\n",
    "                   save_directory=\"./BabyARCDataset/\", \n",
    "                   object_limit=1, noise_level=0, canvas_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repre_dict_1 = demo_dataset.sample_single_canvas_by_core_edges(\n",
    "    OrderedDict([(('obj_0', 'obj_1'), 'IsTouch')\n",
    "                ]), \n",
    "    allow_connect=True, rainbow_prob=0.0, \n",
    "    concept_collection=[\"Fshape\"], \n",
    "    is_plot=True\n",
    ")\n",
    "if repre_dict_1 == -1:\n",
    "    print(\"CANVAS PLACEMENT FAILED!\")\n",
    "else:\n",
    "    in_canvas_1 = Canvas(\n",
    "        repre_dict=repre_dict_1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_canvas_list, _ = OperatorEngine().operator_move(\n",
    "    [in_canvas_1], [[\"obj_0\"]], [[OperatorMoveSpec(autonomous=False,\n",
    "                                                   direction=1, \n",
    "                                                   distance=-1, \n",
    "                                                   hit_type=None, # either wall or agent\n",
    "                                                   linkage_move=False, \n",
    "                                                   linkage_move_distance_ratio=None\n",
    "                                                  )]], \n",
    "    allow_overlap=False, \n",
    "    allow_shape_break=True,\n",
    "    allow_connect=True,\n",
    ")\n",
    "if out_canvas_list == -1:\n",
    "    print(\"OPERATOR FAILED!\")\n",
    "else:\n",
    "    _ = out_canvas_list[0].render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selector tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same Color + IsTouch + Move\n",
    "dataset_engine = \\\n",
    "    BabyARCDataset(pretrained_obj_cache=os.path.join(get_root_dir(), 'concept_env/datasets/arc_objs.pt'),\n",
    "                   save_directory=\"./BabyARCDataset/\", \n",
    "                   object_limit=1, noise_level=0, canvas_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_babyarc_selector_task(\n",
    "    dataset_engine,\n",
    "    selector_dict,\n",
    "    concept_collection=[\"line\", \"Lshape\", \"rectangle\", \"rectangleSolid\"],\n",
    "    is_plot=False,\n",
    "):\n",
    "\n",
    "    canvas_dict = dataset_engine.sample_single_canvas_by_core_edges(\n",
    "        selector_dict,\n",
    "        allow_connect=True, is_plot=False, rainbow_prob=0.0,\n",
    "        concept_collection=concept_collection,\n",
    "    )\n",
    "    if canvas_dict == -1:\n",
    "        return -1\n",
    "    else:\n",
    "        if is_plot:\n",
    "            canvas = Canvas(\n",
    "                repre_dict=canvas_dict\n",
    "            )\n",
    "            canvas.render()\n",
    "\n",
    "    return_dict = OrderedDict({\n",
    "        \"obj_masks\" : {},\n",
    "        \"obj_relations\" : {},\n",
    "    })\n",
    "    for k, v in canvas_dict[\"node_id_map\"].items():\n",
    "        return_dict[\"obj_masks\"][k] = canvas_dict[\"id_object_mask\"][v]\n",
    "    return_dict[\"obj_relations\"] = canvas_dict[\"partial_relation_edges\"]\n",
    "    return_dict[\"image_t\"] = canvas_dict[\"image_t\"]\n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_dict = generate_babyarc_selector_task(\n",
    "    dataset_engine,\n",
    "    selector_dict=OrderedDict(\n",
    "        [(('obj_0', 'obj_1'), 'IsInside'),\n",
    "         (('obj_0', 'obj_2'), 'SameShape')\n",
    "        ]\n",
    "    ),\n",
    "    concept_collection=[\"line\", \"Lshape\"],\n",
    "    is_plot=True,\n",
    ")\n",
    "if return_dict == -1:\n",
    "    print(\"Generation failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Selector + 1 Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_babyarc_task(\n",
    "    dataset_engine,\n",
    "    operator_engine,\n",
    "    canvas_relation,\n",
    "    allow_connect=True, \n",
    "    rainbow_prob=0.0, \n",
    "    example_count=3,\n",
    "    operator=\"Move\", \n",
    "    canvas_size=8,\n",
    "    concept_collection=[\"line\", \"Lshape\", \"rectangle\", \"rectangleSolid\"],\n",
    "    is_torch=True,\n",
    "    debug=False,\n",
    "    parsing_check=False,\n",
    "    single_obj_only=True,\n",
    "    must_change_check=True,\n",
    "):\n",
    "    # Generate canvas in.\n",
    "    repre_dict_list = []\n",
    "    in_canvas_list = []\n",
    "    for i in range(example_count):\n",
    "        repre_dict = dataset_engine.sample_single_canvas_by_core_edges(\n",
    "            canvas_relation, \n",
    "            allow_connect=True, rainbow_prob=0.0, \n",
    "            concept_collection=[\"line\", \"Lshape\", \"rectangle\", \"rectangleSolid\"], \n",
    "            is_plot=False,\n",
    "            parsing_check=parsing_check\n",
    "        )\n",
    "        if repre_dict == -1:\n",
    "            return -1, None, None\n",
    "        repre_dict_list.append(repre_dict)\n",
    "        in_canvas = Canvas(\n",
    "            repre_dict=repre_dict\n",
    "        )\n",
    "        in_canvas_list.append(in_canvas)\n",
    "\n",
    "    # Find common patterns.\n",
    "    pattern_selector_candidates = operator_engine.select_by_common_referred_patterns(\n",
    "        in_canvas_list\n",
    "    )\n",
    "    random.shuffle(pattern_selector_candidates)\n",
    "    found = False\n",
    "    if single_obj_only:\n",
    "        for p_s_c in pattern_selector_candidates:\n",
    "            _len = set([])\n",
    "            for s_o in p_s_c:\n",
    "                _len.add(len(s_o))\n",
    "            if len(_len) == 1 and list(_len)[0] == 1:\n",
    "                pattern_selector = p_s_c\n",
    "                found = True\n",
    "                break\n",
    "    else:\n",
    "        # Randomly sample one.\n",
    "        pattern_selector = random.choice(pattern_selector_candidates)\n",
    "    if not found:\n",
    "        return -1, None, None\n",
    "    \n",
    "    operator_type = None\n",
    "    out_repre_dict_list = []\n",
    "    if operator == \"Move\":\n",
    "        operator_spec = OperatorMoveSpec(autonomous=False,\n",
    "           direction=random.randint(0,3), \n",
    "           distance=random.randint(1, canvas_size//2), \n",
    "           hit_type=None, # either wall or agent\n",
    "           linkage_move=False, \n",
    "           linkage_move_distance_ratio=None\n",
    "        )\n",
    "        \n",
    "        canvas_idx = 0\n",
    "        for in_canvas in in_canvas_list:\n",
    "            out_canvas, _ = operator_engine.operator_move(\n",
    "                [in_canvas], [pattern_selector[canvas_idx]], \n",
    "                [[operator_spec]*len(pattern_selector[canvas_idx])], \n",
    "                allow_overlap=False, \n",
    "                allow_shape_break=False,\n",
    "                allow_connect=allow_connect,\n",
    "            )\n",
    "            if out_canvas == -1:\n",
    "                return -1, None, None\n",
    "            out_canvas = out_canvas[0]\n",
    "            out_repre_dict_list.append(out_canvas.repr_as_dict())\n",
    "            canvas_idx += 1\n",
    "    elif operator == \"Rotate\":\n",
    "        canvas_idx = 0\n",
    "        rotate_types = [\"RotateA\", \"RotateB\", \"RotateC\", \"hFlip\", \"vFlip\", \"DiagFlipA\", \"DiagFlipB\"]\n",
    "        operator_type = random.choice(rotate_types)\n",
    "        for in_canvas in in_canvas_list:\n",
    "            out_canvas, _ = operator_engine.operate_rotate(\n",
    "                [in_canvas], [pattern_selector[canvas_idx]],\n",
    "                operator_tag=f\"#{operator_type}\", \n",
    "                allow_connect=True, \n",
    "                allow_shape_break=False,\n",
    "            )\n",
    "            if out_canvas == -1:\n",
    "                return -1, None, None\n",
    "            out_canvas = out_canvas[0]\n",
    "            out_repre_dict_list.append(out_canvas.repr_as_dict())\n",
    "            canvas_idx += 1\n",
    "\n",
    "    if debug:\n",
    "        print(repre_dict_list)\n",
    "        print(pattern_selector)\n",
    "    \n",
    "    # Consolidate outpus.\n",
    "    input_images = []\n",
    "    for in_dict in repre_dict_list:\n",
    "        input_images.append(in_dict['image_t'])\n",
    "    output_images = []\n",
    "    for out_dict in out_repre_dict_list:\n",
    "        output_images.append(out_dict['image_t'])\n",
    "    \n",
    "    if must_change_check:\n",
    "        # We need to see all canvas changed after operating.\n",
    "        for i in range(len(input_images)):\n",
    "            if torch.equal(input_images[i], output_images[i]):\n",
    "                return -1, None, None\n",
    "    \n",
    "    # Generate ARC json format.\n",
    "    generated_task = (input_images, output_images)\n",
    "    task_json = {}\n",
    "    train = []\n",
    "    test = []\n",
    "    for i in range(len(generated_task[0])):\n",
    "        _in = np.int_(generated_task[0][i].numpy()).tolist()\n",
    "        _out = np.int_(generated_task[1][i].numpy()).tolist()\n",
    "        if i == len(generated_task[0]) - 1: # We default this as the test.\n",
    "            test.append({\n",
    "                'input':_in,\n",
    "                'output':_out\n",
    "            })\n",
    "        else:\n",
    "            train.append({\n",
    "                'input':_in,\n",
    "                'output':_out\n",
    "            })\n",
    "    task_json = {\n",
    "        'test':test,\n",
    "        'train':train\n",
    "    }\n",
    "    if is_torch:\n",
    "        task_json = to_Variable_recur(task_json, type=\"long\")\n",
    "    return task_json, pattern_selector, operator_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slightly modified this as in util\n",
    "def visualize_dataset(dataset, filename=None, is_show=True, title=None, test_output=False, **kwargs):\n",
    "    def to_value(input):\n",
    "        if not isinstance(input, torch.Tensor):\n",
    "            input = input.get_node_value()\n",
    "        return input\n",
    "    length = len(dataset[\"train\"]) + 1\n",
    "    plt.figure(figsize=(7, 3.5 * (length)))\n",
    "    for i, data in enumerate(dataset[\"train\"]):\n",
    "        visualize_matrices(\n",
    "            [to_value(data[\"input\"]), to_value(data[\"output\"])], \n",
    "            num_rows=length, row=i, plt=plt, is_show=is_show, \n",
    "            title=title if i == 0 else None\n",
    "        )\n",
    "    if \"test\" in dataset:\n",
    "        if test_output:\n",
    "            visualize_matrices(\n",
    "                [to_value(dataset[\"test\"][0][\"input\"]), \n",
    "                 to_value(dataset[\"test\"][0][\"output\"])], \n",
    "                images_per_row=2, num_rows=length, row=i+1, \n",
    "                plt=plt, is_show=is_show\n",
    "            )\n",
    "        else:\n",
    "            visualize_matrices(\n",
    "                [to_value(dataset[\"test\"][0][\"input\"])], \n",
    "                images_per_row=2, num_rows=length, row=i+1, \n",
    "                plt=plt, is_show=is_show\n",
    "            )\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename, bbox_inches=\"tight\", **kwargs)\n",
    "    if is_show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More relation with BabyARC objects\n",
    "demo_dataset = \\\n",
    "    BabyARCDataset(pretrained_obj_cache=os.path.join(get_root_dir(), 'concept_env/datasets/arc_objs.pt'),\n",
    "                   save_directory=\"./BabyARCDataset/\", \n",
    "                   object_limit=1, noise_level=0, canvas_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_concepts = OrderedDict({})\n",
    "ensembled_tasks = OrderedDict({})\n",
    "rel_pool = [\"SameAll\", \"SameShape\", \"SameColor\", \"SameRow\", \"SameCol\", \"IsInside\", \"IsTouch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_idx = 0\n",
    "max_itr = 1000000\n",
    "for i in range(max_itr):\n",
    "    \n",
    "    rel1 = random.choice(rel_pool)\n",
    "    rel2 = random.choice(list(set(rel_pool) - set([rel1])))\n",
    "    relations = OrderedDict([(('obj_0', 'obj_1'), rel1),\n",
    "                             (('obj_0', 'obj_2'), rel2)\n",
    "                            ])\n",
    "    generated_task, pattern_selector, operator_type = generate_babyarc_task(\n",
    "        demo_dataset,\n",
    "        OperatorEngine(),\n",
    "        relations,\n",
    "        operator=\"Rotate\",\n",
    "        example_count=3,\n",
    "        debug=False,\n",
    "        parsing_check=True,\n",
    "        single_obj_only=True,\n",
    "    )\n",
    "    if generated_task != -1:\n",
    "        task_concepts[task_idx] = {\n",
    "            \"relations\": relations,\n",
    "            \"operators\": [operator_type]\n",
    "        }\n",
    "        if len(ensembled_tasks) % 100 == 0:\n",
    "            print(f\"generating #{len(ensembled_tasks)} tasks ...\")\n",
    "        ensembled_tasks[task_idx] = copy.deepcopy(generated_task)\n",
    "        task_idx += 1\n",
    "        if task_idx == 10000:\n",
    "            # Complete!\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = \"rotate\"\n",
    "json_dump_tasks_path = f\"./datasets/{operator}-tasks.json\"\n",
    "json_dump_concepts_path = f\"./datasets/{operator}-concepts.json\"\n",
    "torch.save(ensembled_tasks, json_dump_tasks_path)\n",
    "torch.save(task_concepts, json_dump_concepts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_idx, task in ensembled_tasks.items():\n",
    "    relations = \"+\".join([v for v in task_concepts[task_idx][\"relations\"].values()])\n",
    "    operators = \"+\".join(task_concepts[task_idx][\"operators\"])\n",
    "    encode_str = f\"id_{task_idx}_{relations}+{operators}\"\n",
    "    output_path = \"./datasets/babyARC_lv1/\" + encode_str + \".png\"\n",
    "    # generated_task = to_Variable_recur(task, type=\"long\"),\n",
    "    visualize_dataset(\n",
    "        task,\n",
    "        filename=output_path,\n",
    "        test_output=False,\n",
    "        debug=False,\n",
    "        is_show=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_task = to_Variable_recur(generated_task, type=\"long\")\n",
    "visualize_dataset(\n",
    "    ensembled_tasks[0],\n",
    "    test_output=True,\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These codes are for debugging purposes!\n",
    "dataset_engine = demo_dataset\n",
    "operator_engine = OperatorEngine()\n",
    "canvas_relation = OrderedDict([(('obj_0', 'obj_1'), 'IsInside'),\n",
    "             (('obj_0', 'obj_2'), 'SameShape'),\n",
    "            ])\n",
    "example_count=3\n",
    "debug=False\n",
    "parsing_check=True\n",
    "operator = \"Move\"\n",
    "canvas_size = 8\n",
    "allow_connect=True\n",
    "is_torch=True\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    # Generate canvas in.\n",
    "    repre_dict_list = []\n",
    "    in_canvas_list = []\n",
    "    for i in range(example_count):\n",
    "        repre_dict = dataset_engine.sample_single_canvas_by_core_edges(\n",
    "            canvas_relation, \n",
    "            allow_connect=True, rainbow_prob=0.0, \n",
    "            concept_collection=[\"line\", \"Lshape\", \"rectangle\", \"rectangleSolid\"], \n",
    "            is_plot=False,\n",
    "            parsing_check=parsing_check\n",
    "        )\n",
    "        if repre_dict == -1:\n",
    "            break\n",
    "        repre_dict_list.append(repre_dict)\n",
    "        in_canvas = Canvas(\n",
    "            repre_dict=repre_dict\n",
    "        )\n",
    "        in_canvas_list.append(in_canvas)\n",
    "\n",
    "    if repre_dict == -1:\n",
    "        continue\n",
    "        \n",
    "    # Find common patterns.\n",
    "    pattern_selector_candidates = operator_engine.select_by_common_referred_patterns(\n",
    "        in_canvas_list\n",
    "    )\n",
    "    # Randomly sample one.\n",
    "    pattern_selector = random.choice(pattern_selector_candidates)\n",
    "    out_repre_dict_list = []\n",
    "    if operator == \"Move\":\n",
    "        operator_spec = OperatorMoveSpec(autonomous=False,\n",
    "           direction=random.randint(0,3), \n",
    "           distance=random.randint(1, canvas_size//2), \n",
    "           hit_type=None, # either wall or agent\n",
    "           linkage_move=False, \n",
    "           linkage_move_distance_ratio=None\n",
    "        )\n",
    "\n",
    "        canvas_idx = 0\n",
    "        for in_canvas in in_canvas_list:\n",
    "            out_canvas, _ = operator_engine.operator_move(\n",
    "                [in_canvas], [pattern_selector[canvas_idx]], \n",
    "                [[operator_spec]*len(pattern_selector[canvas_idx])], \n",
    "                allow_overlap=False, \n",
    "                allow_shape_break=False,\n",
    "                allow_connect=allow_connect,\n",
    "            )\n",
    "            if out_canvas == -1:\n",
    "                break\n",
    "            out_canvas = out_canvas[0]\n",
    "            out_repre_dict_list.append(out_canvas.repr_as_dict())\n",
    "            canvas_idx += 1\n",
    "    else:\n",
    "        print(\"Not implemented.\")\n",
    "        break\n",
    "\n",
    "    if out_canvas == -1:\n",
    "        continue\n",
    "        \n",
    "    if debug:\n",
    "        print(repre_dict_list)\n",
    "        print(pattern_selector)\n",
    "\n",
    "    # Consolidate outpus.\n",
    "    input_images = []\n",
    "    for in_dict in repre_dict_list:\n",
    "        input_images.append(in_dict['image_t'])\n",
    "    output_images = []\n",
    "    for out_dict in out_repre_dict_list:\n",
    "        output_images.append(out_dict['image_t'])\n",
    "        \n",
    "    # Generate ARC json format.\n",
    "    generated_task = (input_images, output_images)\n",
    "\n",
    "    \n",
    "    task_json = {}\n",
    "    train = []\n",
    "    test = []\n",
    "    for i in range(len(generated_task[0])):\n",
    "        _in = np.int_(generated_task[0][i].numpy()).tolist()\n",
    "        _out = np.int_(generated_task[1][i].numpy()).tolist()\n",
    "        if i == len(generated_task[0]) - 1: # We default this as the test.\n",
    "            test.append({\n",
    "                'input':_in,\n",
    "                'output':_out\n",
    "            })\n",
    "        else:\n",
    "            train.append({\n",
    "                'input':_in,\n",
    "                'output':_out\n",
    "            })\n",
    "    task_json = {\n",
    "        'test':test,\n",
    "        'train':train\n",
    "    }\n",
    "    if is_torch:\n",
    "        task_json = to_Variable_recur(task_json, type=\"long\")\n",
    "        \n",
    "    if generated_task != -1:\n",
    "        len_s = []\n",
    "        for p in pattern_selector:\n",
    "            len_s += [len(p)]\n",
    "        if len(set(len_s)) != 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated_task = to_Variable_recur(generated_task, type=\"long\")\n",
    "visualize_dataset(\n",
    "    task_json,\n",
    "    test_output=True,\n",
    "    debug=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
